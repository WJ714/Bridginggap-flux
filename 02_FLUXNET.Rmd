---
title: "FLUXNET data application"
output:
  html_document: default
  pdf_document: default
date: "2025-08-05"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(
  echo = TRUE,
  fig.width = 11,  # Set the plot width in inches
  fig.height = 4,  # Set the plot height in inches
  warning = FALSE,  # Hide warnings
  message = FALSE   # Hide messages
)
library(data.table)
library(lubridate)
library(dplyr)
library(tidyverse)
library(Kendall)
library(ggplot2)
library(ggpubr)
my_theme <- theme_light(base_size = 14) +
  theme(
    axis.text.x = element_text(size = 12),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", color = "white"),
    plot.background = element_rect(fill = "white", color = "white")
  )
```

# FLUXNET data

-   Variables quick start guide:
    <https://fluxnet.org/data/fluxnet2015-dataset/variables-quick-start-guide/>
-   Data variables: <https://fluxnet.org/data/aboutdata/data-variables/>
-   Full set data product:
    <https://fluxnet.org/data/fluxnet2015-dataset/fullset-data-product/>

# How to save figures using R?

We do not include any codes for saving figures in this tutorial. If you
wish to save figures locally, you can use functions like `ggsave()` (for
ggplot objects) or base R functions such as `png()` or `pdf()`. Here are
some examples:

```{r}
## ggsave
# ggsave("my_figure.png", plot = p, width = 8, height = 6, dpi = 300)

## base R function
# png("my_plot.png", width = 800, height = 600, res = 150)
# plot(x, y)
# dev.off()
```

# Read data from local drive

```{r}
# # please modify the data_dir to your own local working directory
# data_dir = ("G:/My Drive/FLUX-LSM workshop/US-Syv/AMF_US-Syv_FLUXNET_SUBSET_2001-2023_4-6/"); setwd(data_dir)
# 
# # read YY data
# {
#   filename = "AMF_US-Syv_FLUXNET_SUBSET_YY_2001-2023_4-6.csv"
#   setwd(data_dir); df.YY = fread(filename)
#   df.YY$year = as.numeric(df.YY$TIMESTAMP)
#   df.YY <- df.YY %>%
#     mutate(across(everything(), ~na_if(. , -9999)))
# }
# 
# # read MM data
# {
#   df.MM = fread(paste0("AMF_US-Syv_FLUXNET_SUBSET_MM_2001-2023_4-6.csv"))
#   # FLUXNET data uses "-9999" as placeholder for missing data. Replace -9999 with NA across all columns
#   df.MM <- df.MM %>%
#     mutate(across(everything(), ~na_if(. , -9999)))
#   
#   # Timestamp column of flux data is formatted as YYYYMM. We need to change it to a readable timestamp format.
#   df.MM$TIMESTAMP <- ym(as.character(df.MM$TIMESTAMP))
#   
#   # Create columns of year
#   df.MM <- df.MM %>%
#     mutate(year = year(TIMESTAMP), month = month(TIMESTAMP))
# }
# 
# # read DD data
# {
#   df.DD = fread(paste0("AMF_US-Syv_FLUXNET_SUBSET_DD_2001-2023_4-6.csv")) 
#   # FLUXNET data uses "-9999" as placeholder for missing data. Replace -9999 with NA across all columns
#   df.DD <- df.DD %>%
#     mutate(across(everything(), ~na_if(. , -9999)))
#   
#   # Timestamp column of flux data is formatted as YYYYMMDD. We need to change it to a readable timestamp format.
#   df.DD$TIMESTAMP <- ymd(as.character(df.DD$TIMESTAMP))
#   
#   # Create columns of year and month
#   df.DD <- df.DD %>%
#     mutate(year = year(TIMESTAMP), month = month(TIMESTAMP))
# }
# 
# # read HH data
# {
#   setwd(data_dir); df.HH = fread(paste0("AMF_US-Syv_FLUXNET_SUBSET_HH_2001-2023_4-6.csv")) 
#   # FLUXNET data uses "-9999" as placeholder for missing data. Replace -9999 with NA across all columns
#   df.HH <- df.HH %>%
#     mutate(across(everything(), ~na_if(. , -9999)))
#   
#   # Timestamp column of flux data is formatted as YYYYMMDDHHMM. We need to change it to a readable timestamp format.
#   df.HH$TIMESTAMP_END <- ymd_hm(as.character(df.HH$TIMESTAMP_END))
#   
#   # Create columns of year and month
#   df.HH <- df.HH %>%
#     mutate(year = year(TIMESTAMP_END), month = month(TIMESTAMP_END))
# }
```

# Read data on google drive

```{r}
# You can also download data from Google drive, if you have a Google account
library(googledrive)

# Download YY data
{
  file_url <- "https://drive.google.com/file/d/1NMFK0IzCgUInzbdx9xauOjv11Ipv18fL/view?usp=sharing"
  file_id <- googledrive::as_id(file_url)
  temp_file <- tempfile(fileext = ".csv") # Download the file to a temp location
  drive_download(file = file_id, path = temp_file, overwrite = TRUE)
  df.YY <- fread(temp_file)
  df.YY$year = as.numeric(df.YY$TIMESTAMP)
  df.YY <- df.YY %>%
    mutate(across(everything(), ~na_if(. , -9999)))
}
# Download MM data
{
  
  file_url <- "https://drive.google.com/file/d/1Ycqd7S4RatQNXPmP3fBOrW48QINVmpvi/view?usp=sharing"
  file_id <- googledrive::as_id(file_url)
  temp_file <- tempfile(fileext = ".csv") # Download the file to a temp location
  drive_download(file = file_id, path = temp_file, overwrite = TRUE)
  df.MM <- fread(temp_file)
  df.MM <- df.MM %>%
  mutate(across(everything(), ~na_if(. , -9999)))

  # Timestamp column of flux data is formatted as YYYYMM. We need to change it to a readable timestamp format.
  df.MM$TIMESTAMP <- ym(as.character(df.MM$TIMESTAMP))
  df.MM <- df.MM %>% # Create columns of year
    mutate(year = year(TIMESTAMP), month = month(TIMESTAMP))
}

# Download DD data
{
  file_url <- "https://drive.google.com/file/d/1kGu2JTe5afS_6ly9p3xgVFtTVtpmc__4/view?usp=sharing"
  file_id <- googledrive::as_id(file_url)
  temp_file <- tempfile(fileext = ".csv") # Download the file to a temp location
  drive_download(file = file_id, path = temp_file, overwrite = TRUE)
  df.DD <- fread(temp_file)
    # FLUXNET data uses "-9999" as placeholder for missing data. Replace -9999 with NA across all columns
  df.DD <- df.DD %>%
    mutate(across(everything(), ~na_if(. , -9999)))
  
  # Timestamp column of flux data is formatted as YYYYMMDD. We need to change it to a readable timestamp format.
  df.DD$TIMESTAMP <- ymd(as.character(df.DD$TIMESTAMP))
  
  # Create columns of year and month
  df.DD <- df.DD %>%
    mutate(year = year(TIMESTAMP), month = month(TIMESTAMP))
}


# Download HH data
{
  file_url <- "https://drive.google.com/file/d/1oIu4WQxpl49qraD-8_9TfpEwniq3WizE/view?usp=sharing"
  file_id <- googledrive::as_id(file_url)
  temp_file <- tempfile(fileext = ".csv") # Download the file to a temp location
  drive_download(file = file_id, path = temp_file, overwrite = TRUE)
  df.HH <- fread(temp_file)
  df.HH <- df.HH %>%
  mutate(across(everything(), ~na_if(. , -9999)))

  # Timestamp column of flux data is formatted as YYYYMMDDHHMM. We need to change it to a readable timestamp format.
  df.HH$TIMESTAMP_END <- ymd_hm(as.character(df.HH$TIMESTAMP_END))
  
  # Create columns of year and month
  df.HH <- df.HH %>%
    mutate(year = year(TIMESTAMP_END), month = month(TIMESTAMP_END))
}
```

# Required task

## Task 1: annual sums of NEE

-   Variables expressing random uncertainty are identified by the suffix
    \_RANDUNC. One of two methods are used to estimate random
    uncertainty, applied hierarchically;

-   NEE-RANDUNC Method 1 (direct standard deviation method);

-   NEE-RANDUNC Method 2 (median standard deviation method) - For more
    details, please check out Pastorello et al. 2020 NEE_VUT_REF:

-   NEE_VUT_REF, using Variable Ustar Threshold (VUT) for each year,
    reference selected on the basis of the model efficiency (MEF). The
    MEF analysis is repeated for each time aggregation.

```{r}
# create upper and lower bounds
# NEE_VUT_REF_RANDUNC
df.YY$NEE_upper <- df.YY$NEE_VUT_REF + df.YY$NEE_VUT_REF_RANDUNC 
df.YY$NEE_lower <- df.YY$NEE_VUT_REF - df.YY$NEE_VUT_REF_RANDUNC
ylab = expression("NEE" ~ "(" * gC ~ m^{-2} ~ year^{-1} * ")") # YY: sum from daily data

# plot annual sums of NEE across years
ggplot(df.YY, aes(x = year)) +
  geom_ribbon(aes(ymin = NEE_lower, ymax = NEE_upper), fill = "blue", alpha = 0.4) + # random uncertainty 
  geom_line(aes(y = NEE_VUT_REF), color = "black", size = 1) +
  geom_smooth(aes(y = NEE_VUT_REF), method = "lm", color = "red", se = FALSE, linetype = "dashed") + # Trend line
  ylab(ylab) +  
  ggtitle("Annual sums of NEE") + my_theme

# The Mann-Kendall trend test is used to assess whether there is a significant monotonic trend (either increasing or decreasing) in a time series. 
MannKendall(df.YY$NEE_VUT_REF) # When P < 0.05, you can reject the null hypothesis ("no trend").

# plot qualify flags of NEE
ggplot(df.YY, aes(x = as.factor(year), y = NEE_VUT_REF_QC)) +
  geom_bar(stat = "identity", fill = "grey") +
  geom_hline(yintercept = 0.75, linetype = "dashed", color = "red") +
  labs(x = "Year", y = "%", 
       title = "Qualify flags for annual sums") +
  ylim(0, 1) +
  scale_x_discrete(breaks = df.YY$year[seq(1, nrow(df.YY), by = 2)]) +
  my_theme
```

Where to go from here:

-   Interpret the figure and include it in your group presentation.

-   Optional: Plot annual sums of LE and H (value + uncertainty).

-   Optinal: Explore the qualify flags for annual sums of LE and H.

## Task 2: monthly average NEE, GPP, RECO

```{r}
ylab = expression("Carbon flux" ~ "(" * gC ~ m^{-2} ~ d^{-1} * ")") # monthly average

# Create date label for graphing
df.MM <- df.MM %>%
  mutate(
    date = as.Date(paste(year, month, "01", sep = "-"))
  )

# Pivot data for easier plotting
df.MM_long <- df.MM %>%
  mutate(GPP_NT_VUT_REF = -GPP_NT_VUT_REF) %>%  # make GPP negative
  dplyr::select(date, year, GPP_NT_VUT_REF, RECO_NT_VUT_REF, NEE_VUT_REF) %>%
  pivot_longer(cols = c(GPP_NT_VUT_REF, RECO_NT_VUT_REF), names_to = "variable", values_to = "value")

# Create the plot
ggplot() +
  # Bar plots for GPP and RECO
  geom_col(data = df.MM_long, aes(x = date, y = value, fill = variable), position = "dodge") +
  # Line for NEE
  geom_line(data = df.MM, aes(x = date, y = NEE_VUT_REF), color = "black", size = 1) +
  scale_fill_manual(values = c("GPP_NT_VUT_REF" = "#2ca02c", "RECO_NT_VUT_REF" = "#d62728")) +
  labs(x = "Date", y = ylab, fill = "Variable", 
       title = "Daily average flux by month: GPP, RECO (bars) and NEE (line)") + my_theme
```

Where to go from here:

-   Interpret the figures and include them in your group presentation;

-   Optional: You can also create your own figures, e.g. monthly
    anomalies, or diurnal patterns;

## Task 3: qualify flags for half-hourly data

```{r}
df.HH <- df.HH %>% # using half-hourly data
  mutate(
    year = year(TIMESTAMP_END),
    DOY = yday(TIMESTAMP_END) + 
      (hour(TIMESTAMP_END) + minute(TIMESTAMP_END)/60 + second(TIMESTAMP_END)/3600) / 24,
    qc_label = factor(
      NEE_VUT_REF_QC,
      levels = c(0, 1, 2, 3),
      labels = c("Measured (0)", "Good (1)", "Medium (2)", "Poor (3)")
    )
  )

# calculate the percentage of each flag
qc_summary <- df.HH %>%
  group_by(year, qc_label) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(year) %>%
  mutate(
    total = sum(count),
    percent = round(100 * count / total, 1),
    label = paste0(qc_label, ": ", percent, "%")
  )


# barplot of qc_summary (% for different qualify flags) by year
qc_summary %>%
  filter(year >= 2004, year <= 2022) %>%
  ggplot(aes(x = factor(year), y = percent, fill = qc_label)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(
    name = "QC Flag",
    values = c(
      "Measured (0)" = "black",
      "Good (1)" = "green4",
      "Medium (2)" = "orange",
      "Poor (3)" = "red"
    )
  ) +
  scale_x_discrete(breaks = as.character(seq(2004, 2022, by = 2))) +
  labs(
    title = "Summary of NEE Quality Flags",
    x = "Year", y = "Percentage (%)"
  ) + my_theme

  
qc_labels <- qc_summary %>%
  group_by(year) %>%
  summarise(
    qc_text = paste(label, collapse = "\n"),
    .groups = "drop"
  )

data_with_labels <- df.HH %>%
  left_join(qc_labels, by = "year")

# looking into data for one year: plot NEE with QC flags
data_with_labels %>%
  filter(year == 2018) %>% # filter data for one year
  ggplot(aes(x = DOY, y = NEE_VUT_REF, color = qc_label)) +
  geom_point(alpha = 0.6, size = 1) +
  scale_color_manual(
    name = "QC Flag",
    values = c("Measured (0)" = "black",
               "Good (1)" = "green4",
               "Medium (2)" = "orange",
               "Poor (3)" = "red")
  ) +
  labs(
    title = expression("Half hourly FCO"[2]*" and quality flags for a single year"),
    x = "DOY", y = expression(FCO[2] ~ "(" * mu * "mol" ~ m^{-2} ~ s^{-1} * ")")
  ) + my_theme
```

Where to go from here:

-   Interpret the figures and include them in your group presentation;

## Task 4: monthly average meteorological variables

```{r}
# Air Temperature
ggplot() +
  geom_line(data = df.MM, aes(x = date, y = TA_F), color = "orange", size = 1) +
  labs(x = "Date", y = "Temperature (\u00B0C)", fill = "Variable", 
       title = "Monthly Average Air Temperature")+
  my_theme


# Incoming shortwave radiation
ggplot() +
  geom_line(data = df.MM, aes(x = date, y = SW_IN_F), color = "blue", size = 1) +
  labs(x = "Date", y = "SW_IN_F (W/m²)", fill = "Variable", 
       title = "Monthly Average Incoming Shortwave Radiation") +
  my_theme
```

Please check:

-   Is the data consistent? Are there any noticeable outliers?
-   what other important meteorological variables should be checked?

# Bonus task

## Task 1: Light response curve

The light response curve describes how **Net Ecosystem Exchange (NEE)**
responds to incoming light (PPFD – photosynthetic photon flux density).
It is a key tool for quantifying ecosystem carbon uptake
characteristics.A light response curve can provide indicators of:

```         
-   `PPFD`: Photosynthetic photon flux density (μmol m⁻² s⁻¹)
-   `Amax`: Maximum photosynthetic rate at light saturation (μmol
    m⁻² s⁻¹)
-   `alpha`: Curvature parameter describing how quickly
    photosynthesis saturates (unitless)
-   `Rd`: Dark respiration rate (μmol m⁻² s⁻¹)
-   A2000: Because of the trade-off of Amax and alpha, we could use A2000 as the proxy for max photosynthesis capacity.
```

```{r}
data_filtered = df.HH[df.HH$month == 7, ] # specify the period you want like to focus on
data_filtered$PPFD = data_filtered$PPFD_IN
data_filtered$NEE = data_filtered$NEE_VUT_REF

# Function to calculate light response curve for NEE based on the Michaelis-Menten equation
light_response_NEE <- function(PPFD, Amax, alpha, Rd) {
  -((Amax * PPFD) / (alpha + PPFD) - Rd)
} # > The negative sign reflects the convention that **NEE is negative during net CO₂ uptake** (photosynthesis > respiration).

# Fit the model using non-linear least squares 
fit_NEE <- nls(NEE ~ light_response_NEE(PPFD, Amax, alpha, Rd),
               data = data_filtered,
               start = list(Amax = max(-data_filtered$NEE, na.rm = TRUE),
                            alpha = 200, Rd = 2))

# Extract model parameter estimates
params <- coef(fit_NEE)
Amax_est <- round(params["Amax"], 2)
alpha_est <- round(params["alpha"], 2)
Rd_est <- round(params["Rd"], 2)

# Compute NEE at 2000 μmol m⁻² s⁻¹ light intensity
A2000 = Amax_est * 2000/(alpha_est + 2000)

# Generate predicted values from the fitted model
data_filtered$NEE_pred <- predict(fit_NEE, newdata = data_filtered)
ggplot(data_filtered, aes(x = PPFD, y = NEE))  +
  geom_point() +
  geom_line(aes(y = NEE_pred), color = "red", size = 1.2) +  
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey", size = 1) +  
  geom_vline(xintercept = 1800, linetype = "dashed", color = "grey", size = 1) +
  labs(x = expression(PPFD ~ "(" * mu * "mol" ~ m^{-2} ~ s^{-1} * ")"), 
       y = expression(FCO[2] ~ "(" * mu * "mol" ~ m^{-2} ~ s^{-1} * ")")) +
  my_theme

# Function to compute A2000  
fit_light_response_NEE <- function(data) {
  # Skip if not enough data
  if (nrow(data) < 10 || all(is.na(data$NEE))) return(NULL)

  # Michaelis-Menten light response model
  light_response_NEE <- function(PPFD, Amax, alpha, Rd) {
    -((Amax * PPFD) / (alpha + PPFD) - Rd)
  }

  # Try fitting the model, catch failures
  fit_result <- tryCatch({
    nls(NEE ~ light_response_NEE(PPFD, Amax, alpha, Rd),
        data = data,
        start = list(
          Amax = max(-data$NEE, na.rm = TRUE),  # guess based on data
          alpha = 200,
          Rd = 2
        ),
        control = nls.control(maxiter = 100, warnOnly = TRUE)
    )
  }, error = function(e) {
    message("Model failed for one year: ", e$message)
    return(NULL)
  })

  # If fitting was successful, extract A2000
  if (!is.null(fit_result)) {
    params <- coef(fit_result)
    Amax <- params["Amax"]
    alpha <- params["alpha"]
    A2000 <- Amax * 2000 / (alpha + 2000)
    return(data.frame(Amax = Amax, alpha = alpha, Rd = params["Rd"], A2000 = A2000))
  } else {
    return(NULL)
  }
}

# compute A2000 for each year
data_by_year <- split(data_filtered, data_filtered$year)
results_by_year <- lapply(data_by_year, fit_light_response_NEE)
names(results_by_year) <- names(data_by_year)
results_df <- bind_rows(results_by_year, .id = "Year")

ggplot(results_df, aes(x = as.numeric(Year), y = A2000)) +
  geom_line() +
  geom_point() +
  labs(title = "A2000 over Years", x = "Year", 
       y = expression(A2000 ~ "(" * mu * "mol" ~ m^{-2} ~ s^{-1} * ")")) +
  ylim(0,50) + my_theme
```

Where to go from here:

-   Interpret the figures and include them in your group presentation.

-   Optional: explore the seasonal pattern of A2000.

-   Group discussion: What parameters used in land surface models relate
    to light use and photosynthesis?

## Task 2: Ecosystem water budget

-   Ecosystem water use is affected by vegetation type and age,
    climate/seasonality, and water availability, and in some cases,
    presence of environmental stress. Looking at the long-term trend of
    the balance between input (precipitation) and outputs
    (evapotranspiration) of water in the ecosystem provides important
    information about its interaction with the environment. We can
    generally estimate the ecosystem water budget by looking at ET and P
    which are both derived from flux tower data. We will only look at
    the growing season ecosystem water budget (months 5 to 10; except
    for Br-Sa1 which is from months 10 to 5)

-   ET = Evapotranspiration (the sum of evaporation from soil +
    transpiration from plants)

-   P = Precipitation (all water input from rain/snow).

ET is derived from latent heat flux (LE) using the formula:

The **evapotranspiration (ET)** is derived from latent heat flux (LE)
using the following equation:

$$
ET = \frac{LE}{\rho_w \cdot \lambda}
$$

Where:

-   $ET$: Evapotranspiration *(m s⁻¹ or mm s⁻¹)*
-   $LE$: Latent heat flux *(W m⁻² = J s⁻¹ m⁻²)*
-   $\rho_w$: Density of water = 1000 kg m⁻³
-   $\lambda$: Latent heat of vaporization = 2.26 × 10⁶ J kg⁻¹

```{r}
# Constants
rho_w <- 1000         # kg/m3 density of water
lambda <- 2.26e6       # J/kg latent heat of vaporization
seconds_per_day <- 86400

# Calculate ET in mm/day from LE_F_MDS
df.DD <- df.DD %>%
  mutate(
    ET_mm_day = (LE_F_MDS * seconds_per_day) / (rho_w * lambda) *1000 #convert from m to mm of water
  )

# Summarize total ET and P per year (Growing season only)
annual_summary <- df.DD %>%
  filter(month %in% 5:10) %>%  # Growing season (May to October in N hemisphere). If working on Br-Sa1, change to
  group_by(year) %>%
  summarise(
    total_ET_mm = sum(ET_mm_day, na.rm = TRUE),
    total_precip_mm = sum(P_F, na.rm = TRUE),
    n_days = sum(!is.na(ET_mm_day)),
    .groups = "drop") %>%
  mutate(ET_over_P =  total_ET_mm / total_precip_mm)

#if working on Br-Sa1, use this code
#annual_summary <- df.DD %>%
  #filter(month %in% c(9:12, 1:5)) %>%
  #mutate(year = if_else(month >= 9, year + 1, year)) %>%  # assign Sept–Dec to next year
  #group_by(year) %>%
  #summarise(
    #total_ET_mm = sum(ET_mm_day, na.rm = TRUE),
    #total_precip_mm = sum(P_F, na.rm = TRUE),
    #n_days = sum(!is.na(ET_mm_day)),
    #.groups = "drop"
 #) %>%
  #mutate(ET_over_P = if_else(total_precip_mm > 0, total_ET_mm / total_precip_mm, NA_real_))


annual_long <- annual_summary %>%
  select(year, total_ET_mm, total_precip_mm) %>%
    pivot_longer(cols = c(total_ET_mm, total_precip_mm),
               names_to = "variable",
               values_to = "value")

### plot the annual trend
ggplot(annual_long, aes(x = year, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
  scale_fill_manual(values = c("total_ET_mm" = "#D55E00", "total_precip_mm" ="#0072B2" ),
                    labels = c("ET", "Precipitation")) +
  labs(x = "Month", y = "Water (mm)", fill = "Variable",
       title = "Annual Evapotranspiration and Precipitation") +
  my_theme

### plot annual ET/P trend
ggplot(annual_summary, aes(x = year, y = ET_over_P)) +
  geom_line(color = "#009E73", size = 1.2) +  
  geom_point(color = "black") +
  geom_hline(yintercept = 1, color = "red", linetype = "dashed", size = 1) + 
  labs(title = "Annual ET/P Ratio",
       x = "Year",
       y = "ET/P") +
  my_theme

```

Where to go from here:

-   Interpret the figure and include it in your group presentation.

## Task 3: Energy balance closure

The **energy balance closure equation** is used to evaluate how well the
measured energy components at an eddy covariance site balance. The
standard form is:

$$
R_n - G = H + LE
$$

Where:

-   $R_n$: Net radiation *(W m⁻²)*
-   $G$: Ground heat flux *(W m⁻²)*
-   $H$: Sensible heat flux *(W m⁻²)*
-   $LE$: Latent heat flux *(W m⁻²)*

A commonly used metric is the **closure ratio**, defined as:

$$
\text{Closure Ratio} = \frac{H + LE}{R_n - G}
$$

This ratio should ideally be close to **1**.\
Values significantly below 1 suggest underestimation of turbulent fluxes
($H + LE$), possibly due to:

-   Measurement errors
-   Missing energy storage terms
-   Unaccounted biophysical or soil processes

```{r}
xlab  = expression(Rn+G~'('*W~m^{-2}*')')
ylab = expression(H+LE~'('*W~m^{-2}*')')

# check if there are NAs in NETRAD, G, H and LE
{
  # Calculate missing percentage by year
  na_pct <- df.HH %>%
    group_by(year) %>%
    summarise(
      NETRAD = mean(is.na(NETRAD)) * 100,
      G_F_MDS = mean(is.na(G_F_MDS)) * 100,
      H_F_MDS = mean(is.na(H_F_MDS)) * 100,
      LE_F_MDS = mean(is.na(LE_F_MDS)) * 100
    ) %>%
    pivot_longer(cols = -year, names_to = "variable", values_to = "na_percent")
  
  # Plot heatmap
  ggplot(na_pct, aes(x = factor(year), y = variable, fill = na_percent)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "white", high = "skyblue", name = "Missing %") +
    labs(x = "Year", y = "Variable", title = "Heatmap of Missing Data Percentage") +
    my_theme +
    theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 1))
}
# data frame for plotting
df.plot = data.frame(v1 = df.HH$NETRAD - df.HH$G_F_MDS, 
                v2 = df.HH$H_F_MDS + df.HH$LE_F_MDS,
                year = df.HH$year)

ggscatter(
  data = df.plot,
  x = "v1",  y = "v2",      
  color = "grey",
  add = "reg.line",
  add.params = list(color = "black", size = 1),  # regression line
  conf.int = TRUE, cor.coef = TRUE,
  cor.coeff.args = list(size = 6),
  title = "Energy balance closure"
) +
stat_regline_equation(
  aes(label = ..eq.label..),
  label.x = -250, label.y = 600, # adjust the position if needed
  size = 6
) + 
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed", size = 1) +
  xlab(xlab) + ylab(ylab) +
  xlim(-250, 800) + ylim(-250,800) # adjust the limits if needed

# Calculate closure ratio for each year
df.summary <- df.plot %>%
  filter(!is.na(v1), !is.na(v2)) %>%
  mutate(closure_ratio = v2 / v1) %>%
  group_by(year) %>%
  summarise(mean_closure = mean(closure_ratio, na.rm = TRUE))

ggplot(df.summary, aes(x = year, y = mean_closure)) +
  geom_col(fill = "grey") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Energy Balance Closure Ratio by Year",
    x = "Year", y = "Closure Ratio (unitless)"
  ) + my_theme
```

Where to go from here:

-   Interpret the figures and include them in your group presentation.

# References

-   Pastorello, Gilberto, et al. "The FLUXNET2015 dataset and the
    ONEFlux processing pipeline for eddy covariance data." Scientific
    data 7.1 (2020): 225.
